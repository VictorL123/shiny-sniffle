# -*- coding: utf-8 -*-
"""Full_list_car_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EosdizNOaPctQE6w1Qpvbu3emU5PnaSm

# **Car Price ML Project**

## **Import data**
"""

#This section of code suppresses all warnings so that the output is clear and visible
#The warnings suppressed are about deprecated functions used in this program

import warnings
warnings.filterwarnings("ignore")

#Here I have imported libraries, which can then be used

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#I import the dataset from my github
df = pd.read_csv('https://raw.githubusercontent.com/VictorL123/shiny-sniffle/main/Car_price_full_list%20-%20Copy.csv')
#The dataset is outputted here
df

"""## **Data preparation**

---

### Data conversion into denary
"""

#This process is necessary as machine learning models cannot take inputs from string
#Therefore I replace all string values with designated integers

df['fuelType'].replace({'Diesel':0, 'Petrol':1, 'Hybrid':2, 'Electric':3, 'Other':4}, inplace=True)
df['transmission'].replace({'Automatic':0, 'Manual':1, 'Semi-Auto':2, 'Other':3}, inplace=True)

#The dataset now has encoded fuel types and transmission types
df

"""### Generating dummy variables"""

#To convert the car models into integers, I used One Hot Encoding, in the form of dummy variables

df = pd.get_dummies(df)
df

"""### Data seperation as X and y"""

#I need to seperate the independent variables and the dependent variable, which is price
y = df['price']

#This is shown here
y

#Similarly, the independent variables are seperated here

X = df.drop('price', axis=1)
X

"""### Data splitting"""

#The dataset must be then split into training and testing data, with the split at 0.8:0.2

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

#The training data of the independent variables are shown, in random order

X_train

#The testing data of the independent variables are shown, in random order

X_test

#The actual price values for the training data
y_train

#The actual price values for the testing data
y_test

"""## **Data presentation**

---

### Car Price spread and distribution
"""

#To see the spread of car price, we use a plotting library (matplotlib.pyplot) to show a box plot

plt.title('Spread of Car Price')
sns.boxplot(y=df.price)
plt.show()
print(df.price.describe())

#The same plotting library is used for a distribution plot

plt.title('Car Price Distribution Plot')
sns.distplot(df.price)
plt.show()

"""### Visualisation of variables affecting car price"""

#I have made a function which plots an independent variable against the dependent variable (price)

def two_variable_plot(x_axis, y_axis) :
  sns.pairplot(df,x_vars=x_axis,y_vars=y_axis,height=4,aspect=1,kind="scatter")
  plt.show()

#I set the dependent variable to the price

y_vars=['price']

"""### Mileage, Engine Size and Year affecting price"""

#The graph function is called with the independent variables being mileage, engine size and year of manufacture

x_vars=['mileage', 'engineSize', 'year']
two_variable_plot(x_vars,y_vars)

#This deletes the anomalous result seen in the year to price graph

df = df.drop(4951, axis=0)
x_vars=['mileage', 'engineSize', 'year']
two_variable_plot(x_vars,y_vars)

"""# **Model Building**

---

## **Linear Regression**

### Training the model
"""

#This imports the Linear Regression model from the sklearn library
from sklearn.linear_model import LinearRegression

#The training data is then fitted into the Linear Regression model
lr = LinearRegression()
lr.fit(X_train, y_train)

"""### Applying the model to make a prediction"""

#The predicted prices are then assigned to the two variables
y_lr_train_pred = lr.predict(X_train)
y_lr_test_pred = lr.predict(X_test)

#The training predictions using Linear Regression model are shown
y_lr_train_pred

#The test predictions using Linear Regression model are shown
y_lr_test_pred

"""### Evaluate model performance"""

#The mean squared error function is imported, along with R squared
from sklearn.metrics import mean_squared_error, r2_score

#Both functions are then used with the data to produce values for mean squared error (MSE) and r squared (R2)
lr_train_mse = mean_squared_error(y_train, y_lr_train_pred)
lr_train_r2 = r2_score(y_train, y_lr_train_pred)
lr_test_mse = mean_squared_error(y_test, y_lr_test_pred)
lr_test_r2 = r2_score(y_test, y_lr_test_pred)

#The MSE and R2 values are outputted in the form of a table

lr_results = pd.DataFrame(['Linear regression', lr_train_mse, lr_train_r2, lr_test_mse, lr_test_r2]).transpose()
lr_results.columns = ['Method', 'Training MSE', 'Training R2', 'Test MSE', 'Test R2']
lr_results

"""## **Random Forest**

### Training the model
"""

#The Random Forest model is imported from the sklearn library
from sklearn.ensemble import RandomForestRegressor

#The Random Forest model is fitted with the training data
rf = RandomForestRegressor(random_state=100)
rf.fit(X_train, y_train)

"""### Applying the model to make a prediction"""

#The predicted prices are then assigned to the two variables
y_rf_train_pred = rf.predict(X_train)
y_rf_test_pred = rf.predict(X_test)

#The training predictions using Random Forest model are shown
y_rf_train_pred

#The test predictions using Random Forest model are shown
y_rf_test_pred

"""### Evaluate model performance"""

#The MSE and R2 values are then calculated using the same function as previously used

rf_train_mse = mean_squared_error(y_train, y_rf_train_pred)
rf_train_r2 = r2_score(y_train, y_rf_train_pred)
rf_test_mse = mean_squared_error(y_test, y_rf_test_pred)
rf_test_r2 = r2_score(y_test, y_rf_test_pred)

#These values are then outputted in the form of a table
rf_results = pd.DataFrame(['Random forest', rf_train_mse, rf_train_r2, rf_test_mse, rf_test_r2]).transpose()
rf_results.columns = ['Method', 'Training MSE', 'Training R2', 'Test MSE', 'Test R2']
rf_results

"""## **Model comparisons**"""

#The MSE and R2 values of both models are then outputted together, to allow for comparisons

df_models = pd.concat([lr_results, rf_results], axis=0)
df_models.reset_index(drop=True)

#The Random Forest model is more accurate - Lower MSE
#The Random Forest model has a better fit - Higher R2

#Therefore, the Random Forest model is preferred over the Linear Regression model

"""## **Data visualisation of prediction results**"""

#Graph is created using matplotlib.plotpy library to show correlation between the predicted price and the actual price

plt.figure(figsize=(5,5))
plt.scatter(x=y_train, y=y_rf_train_pred, alpha=0.4)

z=np.polyfit(y_train, y_rf_train_pred, 1)
p= np.poly1d(z)

plt.plot(y_train, p(y_train), '#F8766D')

plt.ylabel('Predicted price')
plt.xlabel('Actual price')

#The headings of the table is saved, to allow asignment for user's data in a dictionary

price = df[df['price']==0]
price

"""# **Application of model**

---

### Function using Random Forest model with new data
"""

#This function uses the Random Forest model to predict the price for a new set of data

def make_ind_prediction(data):
  data = data.values.reshape(1,-1)
  prediction = rf.predict(data)
  prediction = np.round(prediction,2)
  return prediction

"""### Recognition of user's car model"""

#This function is needed to convert the user's input into the same format as in the dataset

def recognise_model():
  model=input("What model is your car:")
  abnormalities = ["180", "200", "220"]
  if model in abnormalities:
    model1="model_"+model
    find_model(model1)
  else:
    model1="model_ "+ model
    find_model(model1)

#This function stores all the features into a list, which can then be searched to find matching models
#A matching model means that there is data for the Random Forest model to accurately predict a price
#This function rejects any models which cannot be found in the dataset, and allows the user to input a model again

def find_model(model1):
    global list
    list = []
    for i in price:
      list.append(i)
    if model1 in list:
      index = list.index(model1)
      print("Model recognised")
      global model2
      model2 = model1
    else:
      print("Model not recognised.")
      recognise_model()

recognise_model()

"""### Allow user to input details about the car"""

14#A dictionary is created with all the categories, allowing for values to be entered
#The values for the categories must be first initialised to 0
new_car={category: "0" for category in list}

#The price category and price value in the dictionary is deleted
#This is because the model is not trained to accept the price, only to calculate the price
del new_car["price"]

#The user can input their new set of data
year = int(input("What year was your car manufactured: "))
transmission = int(input("What type of transmission is your car (Enter 0 for Automatic, 1 for Manual, 2 for Semi-Automatic and 3 for Other): "))
mileage = int(input("What is your car's mileage: "))
fuelType = int(input("What is the fuel type of your car (Enter 0 for Diesel, 1 for Petrol, 2 for Hybrid, 3 for Electric and 4 for Other): "))
tax = float(input("What is your car's g/km CO2 emisssions: "))
mpg = float(input("What is your car's mpg: "))
engineSize = float(input("What is your car's engine size: "))

#The dictionary is updated with these values
new_car.update(
    [
        ('year', year),
        ('transmission', transmission),
        ('mileage', mileage),
        ('fuelType', fuelType),
        ('tax', tax),
        ('mpg', mpg),
        ('engineSize', engineSize),
        (model2, 1)
    ]
)

"""### Apply user's data to the model"""

#The dictionary is converted into an array, so that it can be used
new_car = pd.Series(new_car)

#The prediction function is called with the new data
cost = make_ind_prediction(new_car)

#The prediction is converted to string
cost = str(cost[0])

#The predicted price is then outputted
print("The predicted price is Â£" + cost)